---
title: "p8105_hw6_xx2416"
author: "Xicheng Xie"
date: "2022-11-29"
output: github_document
---

```{r setup, message=FALSE}
library(tidyverse)
library(purrr)
library(modelr)
library(mgcv)
```

# Problem 1

* Read the dataset
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())


```

* Doing the bootstrap
```{r}
weather_boots<-
weather_df %>% 
  bootstrap(n=5000) %>% 
  mutate(
    models=map(strap,~lm(tmax~tmin,data = .x)),
    results1=map(models,broom::tidy),
    results2=map(models,broom::glance))

```

* Produce estimate of log(beta^0*beta^1)
```{r}
log_beta<-
  weather_boots %>% 
  select(.id,results1) %>% 
  unnest(results1) %>% 
  select(.id,term,estimate) %>% 
  pivot_wider(names_from = "term",
              values_from = "estimate") %>% 
  rename(beta0='(Intercept)',beta1='tmin') %>% 
  mutate(log_beta=log(beta0*beta1)) 

log_beta %>%
  pull(log_beta) %>% 
  quantile(c(0.025,0.975))
  
log_beta %>% 
  ggplot(aes(x=log_beta))+
  geom_density()
```

* Produce estimate of r^2
```{r}
r_squred<-
  weather_boots %>% 
  select(.id,results2) %>% 
  unnest(results2) %>% 
  select(.id,r.squared)

r_squred %>% pull(r.squared) %>% quantile(c(0.025,0.975))

r_squred %>% 
  ggplot(aes(r.squared))+
  geom_density()
```

# Problem 2

* Read and clean the raw dataset.
```{r}
homicide_df<-
  read.csv("homicide-data.csv") %>% 
  mutate(city_state=str_c(city,state,sep=','),
         resolved=as.numeric(disposition=="Closed by arrest"),
         victim_age=as.numeric(victim_age)) %>% 
  filter(!city_state %in% c("Dallas,TX","Phoenix,AZ","Kansas City,MO","Tulsa,AL")) %>%
  filter(victim_race %in% c("White","Black")) 
```

* Fit a logistic regression for the city of Baltimore,MD
```{r}
baltimore_df<-
  homicide_df %>% 
  filter(city_state=="Baltimore,MD") %>% 
  select(resolved, victim_age, victim_race, victim_sex)

fit_logistic<-
  baltimore_df %>% 
  glm(resolved~victim_age+victim_race+victim_sex,data=., family = binomial())

fit_logistic %>% 
  broom::tidy() %>% 
  mutate(OR=exp(estimate),
         CI_lower=exp(estimate-std.error*qnorm(0.975)),
         CI_upper=exp(estimate+std.error*qnorm(0.975))) %>% 
  select(term,OR,starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```

Based on the table, the estimate of the adjusted OR for solving homicides comparing male victims to female victims is `0.426`, and the 95% confidence interval is from `0.325` to `0.558`, which means homicides in which the victim is male are significantly less likely to be resolved than those in which the victim is female.

* Run `glm` for each of the cities in the `homicide_df`, and extract the adjusted OR and CI for solving homicides comparing male victims to female victims.
```{r}
fit_logistic_all<-
  homicide_df %>% 
  nest(data=-city_state) %>% 
  mutate(
    models=map(data,~glm(resolved~victim_age+victim_race+victim_sex,data=.x, family = binomial())),
    results=map(models,broom::tidy)
  ) %>% 
  select(city_state,results) %>% 
  unnest(results) 

# Extract the estimate ORs and CIs for victim_sexMale 
results_victim_sexMale<-
  fit_logistic_all %>% 
  filter(term=="victim_sexMale") %>% 
  mutate(OR=exp(estimate),
         CI_lower=exp(estimate-std.error*qnorm(0.975)),
         CI_upper=exp(estimate+std.error*qnorm(0.975))) %>% 
  select(city_state,OR,starts_with("CI")) 

# Make a plot
results_victim_sexMale%>%
  mutate(city_state=fct_reorder(city_state,OR)) %>% 
  ggplot(aes(x=city_state,y=OR))+
  geom_point()+
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper))+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

# Problem 3

* load and clean the data.
```{r}
birthweight_df<-read.csv("birthweight.csv") %>%
  janitor::clean_names() %>%
  mutate(babysex=as.factor(babysex),
         frace=as.factor(frace),
         malform=as.factor(malform),
         mrace=as.factor(mrace))


map(birthweight_df,~sum(is.na(.x)))
```
This dataset contains 4342 rows and 20 columns, there is no missing data. 

* Build the model
A article published in `NCBI` did a Community Based Study about `the Factors Affecting Birth Weight of a Newborn` [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3390317/]. The present study revealed that maternal illiteracy, exposure to passive smoking, late child bearing, shorter inter-pregnancy interval, previous LBW baby, maternal weight, weight gain during pregnancy, PIH, high risk pregnancy and late antenatal registration were the risk factors significantly associated with the birth weight of a newborn. Meanwhile, the race of both parents and the malformation situation are important factors to adjust the model. As such, I include `fincome`, `smoken`, `momage`,`pnumlbw`,`delwt`,`wtgain`,`babysex`, `malform`, `gaweeks`, `mrace`, and `frace`.
```{r}
lm(bwt~fincome+smoken+momage+pnumlbw+delwt+wtgain+babysex+malform+gaweeks+mrace+frace,data=birthweight_df) %>% summary()
```
Based on the results, the factors including `fincome`, `momage`, `pnumlbw`, `malform`, and `frace` are not significant at the level of 0.05. Hence I decide to delete these variables to make the model more clean and reasonable.
```{r}
model_fit1<-lm(bwt~smoken+delwt+wtgain+babysex+gaweeks+mrace,data=birthweight_df)

birthweight_df %>% 
  modelr::add_residuals(model_fit1) %>% 
  modelr::add_predictions(model_fit1) %>% 
  ggplot(aes(x=pred,y=resid))+
  geom_point(alpha=0.5)+
  geom_smooth(se = F, color = "red", method = "lm")
```

* Fit other models and make the comparision in terms of the cross-validated prediction error.
```{r}
cv_df<-
  crossv_mc(birthweight_df,100) %>% 
  mutate(
    train=map(train,as_tibble),
    test=map(train,as_tibble)
  ) %>% 
  mutate(
    model1=map(train,~lm(bwt~smoken+delwt+wtgain+babysex+gaweeks+mrace,data=.x)),
    model2=map(train,~lm(bwt~gaweeks + blength,data = .x)),
    model3=map(train,~lm(bwt~bhead + blength + babysex+bhead*blength+bhead*babysex+blength*babysex+bhead * blength * babysex,data=.x))
  ) %>% 
  mutate(
    rmse_model1=map2_dbl(model1,test,~rmse(model = .x,data = .y)),
    rmse_model2=map2_dbl(model2,test,~rmse(model = .x,data = .y)),
    rmse_model3=map2_dbl(model3,test,~rmse(model = .x,data = .y))
  )

cv_df %>% 
  select(starts_with("rmse")) %>%
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  mutate(model=fct_inorder(model)) %>% 
  ggplot(aes(x=model,y=rmse))+
  geom_violin()
```
Based on the RSME plot, it shows that model3 is the best model with the lowest `RSME`. The model1 which is build based on the paper clearly needs some improvement. But it makes sense, considering the paper is a in community study in Rural Karnataka, India, and this dataset we used were gathered in American. Model 3 use head circumference, length, sex, and all interactions (including the three-way interaction) between these. In my humble opinion, the model1's con is that the model focus mainly on socialdemographic factors but ingores certain phycical factors which are much more intuitive, such as head circumference and length. 



